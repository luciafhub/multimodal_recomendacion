{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Particionado Estratificado del Dataset para Recomendación\n",
        "\n",
        "*Autora: Lucía Fernández Rodríguez*\n",
        "\n",
        "*Fecha: 2025*\n",
        "\n",
        "Este notebook prepara los datos para el entrenamiento y evaluación de un sistema de recomendación a partir de un conjunto de reseñas con embeddings generados previamente.\n",
        "\n",
        "Se garantiza que cada usuario tenga al menos una reseña en el conjunto de entrenamiento y que todos los restaurantes estén representados en dicho conjunto.\n",
        "\n",
        "A continuación, se completa la partición siguiendo una proporción estándar del 80% para entrenamiento, 10% para validación y 10% para test. El resultado final se guarda en tres archivos que pueden ser utilizados en modelos de predicción personalizados."
      ],
      "metadata": {
        "id": "kCbSlQWcYrcn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importación de librerías"
      ],
      "metadata": {
        "id": "Pf85unU5aHXG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "k0BAZjLJaG88"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Carga del Dataset y Reasignación de identificadores"
      ],
      "metadata": {
        "id": "JeCzvl7eaQgG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Carga del dataset que ya contiene embeddings de texto e imagen, y otras columnas relevantes\n",
        "df = pd.read_pickle(\"/kaggle/input/gijon_embed.pkl\")\n",
        "\n",
        "# Reasignación de IDs: convierte los identificadores de usuario y restaurante a valores numéricos consecutivos\n",
        "df['user_id_new'] = pd.factorize(df['userId'])[0]\n",
        "df['restaurant_id_new'] = pd.factorize(df['restaurantId'])[0]"
      ],
      "metadata": {
        "id": "ID2ZavCOZ_cR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fijar semilla para garantizar reproducibilidad\n",
        "np.random.seed(10)\n",
        "\n",
        "# Mezcla aleatoriamente todas las reseñas para evitar sesgos por orden\n",
        "df = df.sample(frac=1, random_state=10).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "EPeX8uXea4K3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Selección Inicial: Al Menos una Reseña por Usuario y Restaurante en Train"
      ],
      "metadata": {
        "id": "NXjNIE6fa89m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fase 1: asegurar que cada usuario esté representado al menos una vez en el conjunto de entrenamiento\n",
        "# Esto evita que haya usuarios en validación o test que el modelo nunca haya visto durante el entrenamiento\n",
        "train_indices = []\n",
        "holdout_indices = []\n",
        "\n",
        "for user_id, group in df.groupby('user_id_new'):\n",
        "    indices = group.index.tolist()\n",
        "    if len(indices) == 1:\n",
        "        # Si el usuario solo tiene una reseña, se asigna directamente a train\n",
        "        train_indices.extend(indices)\n",
        "    else:\n",
        "        # Si tiene varias, se selecciona una al azar para train y el resto para holdout (val/test)\n",
        "        pick = np.random.choice(indices, 1, replace=False)\n",
        "        train_indices.extend(pick)\n",
        "        holdout_indices.extend(list(set(indices) - set(pick)))\n",
        "\n",
        "train_df = df.loc[train_indices].copy()\n",
        "holdout_df = df.loc[holdout_indices].copy()\n",
        "\n",
        "# Fase 2: asegurar que todos los restaurantes estén presentes en el conjunto de entrenamiento\n",
        "# Esto es importante porque si un restaurante aparece solo en validación/test, el modelo no puede aprender nada sobre él\n",
        "train_restaurants = set(train_df['restaurant_id_new'].unique())\n",
        "missing_restaurants = set(holdout_df['restaurant_id_new'].unique()) - train_restaurants\n",
        "\n",
        "for rest_id in sorted(missing_restaurants):\n",
        "    candidates = holdout_df[holdout_df['restaurant_id_new'] == rest_id]\n",
        "    if not candidates.empty:\n",
        "        # Se mueve una reseña de ese restaurante desde holdout a train\n",
        "        chosen_idx = np.random.choice(candidates.index, 1, replace=False)\n",
        "        train_df = pd.concat([train_df, holdout_df.loc[chosen_idx]], ignore_index=True)\n",
        "        holdout_df = holdout_df.drop(index=chosen_idx)"
      ],
      "metadata": {
        "id": "QA97c3nCa8Zr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## División en las tres particiones míticas (80-10-10)"
      ],
      "metadata": {
        "id": "-reI09hxbQC_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sbuwl2g9YphL"
      },
      "outputs": [],
      "source": [
        "# Fase 3: aumentar el conjunto de entrenamiento hasta que represente el 80% del total de datos\n",
        "# Esto se hace para tener una proporción estándar 80-10-10 (train-val-test)\n",
        "train_target_size = int(0.80 * len(df))\n",
        "if len(train_df) < train_target_size:\n",
        "    extra_needed = train_target_size - len(train_df)\n",
        "    extra_samples = holdout_df.sample(n=extra_needed, random_state=10)\n",
        "    train_df = pd.concat([train_df, extra_samples], ignore_index=True)\n",
        "    holdout_df = holdout_df.drop(index=extra_samples.index)\n",
        "\n",
        "# Fase 4: dividir el 20% restante entre validación y test (10% cada uno)\n",
        "# Este conjunto ya se ha mezclado aleatoriamente, así que lo partimos por la mitad\n",
        "holdout_df = holdout_df.sample(frac=1, random_state=10).reset_index(drop=True)\n",
        "val_size = int(0.5 * len(holdout_df))\n",
        "val_df = holdout_df.iloc[:val_size].copy()\n",
        "test_df = holdout_df.iloc[val_size:].copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Selección de columnas y guardado de archivos"
      ],
      "metadata": {
        "id": "s177bK92bYcu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Selección de columnas relevantes para el análisis o el entrenamiento posterior\n",
        "cols_to_keep = ['images', 'rating', 'restaurantId', 'reviewId', 'text', 'userId',\n",
        "                'sel_image_url', 'image_emb', 'text_emb']\n",
        "\n",
        "train_df = train_df[cols_to_keep + ['user_id_new', 'restaurant_id_new']]\n",
        "val_df   = val_df[cols_to_keep + ['user_id_new', 'restaurant_id_new']]\n",
        "test_df  = test_df[cols_to_keep + ['user_id_new', 'restaurant_id_new']]\n",
        "\n",
        "# Guardado de los datasets para uso posterior\n",
        "train_df.to_pickle(\"/kaggle/working/train_v80.pkl\")\n",
        "val_df.to_pickle(\"/kaggle/working/val_v10.pkl\")\n",
        "test_df.to_pickle(\"/kaggle/working/test_v10.pkl\")\n",
        "\n",
        "# Verificación del resultado: tamaños y proporciones\n",
        "print(\"\\n Datos guardados con éxito.\")\n",
        "print(f\"Train: {train_df.shape}\")\n",
        "print(f\"Val:   {val_df.shape}\")\n",
        "print(f\"Test:  {test_df.shape}\")\n",
        "\n",
        "total = len(df)\n",
        "print(f\"\\n Porcentajes aproximados:\")\n",
        "print(f\"Train: {len(train_df)/total:.2%}\")\n",
        "print(f\"Val:   {len(val_df)/total:.2%}\")\n",
        "print(f\"Test:  {len(test_df)/total:.2%}\")"
      ],
      "metadata": {
        "id": "IDvwRq1AbXe6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}